1. MLR for English 

  #(trainingGraphs) = 10008
  #(developmentGraphs) = 1648

  #(features with count >= 3) = 161160
  #(features with count >= 2) = 257363
  88 transitions

  Need to train with at least 64GB of RAM. 

  numFeatures = 4096
    0.8743102047676405, 0.9213244056063099
    uas = 0.20877873427301108, las = 0.18867656796897173
    uas = 0.1900964622231062, las = 0.1722086865723591
  x-40:


  numFeatures = 8192
  0.8648981764195075, 0.9425750439766215
  uas = 0.27045691041528713, las = 0.24860467316242552
  uas = 0.26330706312308877, las = 0.24340551425801157

  numFeatures = 16384
  0.8467464074623939, 0.9717733927254156
  uas = 0.37148803329864727, las = 0.340317850723678
  uas = 0.3912127389801855, las = 0.36916067921338536

  numFeatures = 32768
    0.8356816717555113,  0.9886441014583215
    uas = 0.5043515277646391, las = 0.4639579982972283
    uas = 0.5805260671754966, las = 0.5614822365313378

  numFeatures = 65536
    0.8359057676685622, 0.9949994325597231
    uas = 0.6147005959701068, las = 0.5706650269605524
    uas = 0.8114698058324838, las = 0.8027683166347612

  numFeatures = 80000
    0.8354295638533292, 0.9961307666118141
    uas = 0.6332891873994891, las = 0.5898685081827642
    uas = 0.8687442508017801, las = 0.862789946050767

  numFeatures = 131072 (Current model on CEFD)
    0.8322361970923555, 0.9975600068092834
    uas = 0.6479992432125626, las = 0.6043893671365055
    uas = 0.9415322079407304, las = 0.9389279765308406

  numFeatures = 200000
    0.8294349981792207, 0.9983083186744595
    uas = 0.6709866616214171, las = 0.6265253996783653
    uas = 0.9853317753524103, las = 0.9844491957337842

  numFeatures = 262144 (247670)
    0.8264937393204291, 0.9984679112523407
    uas = 0.6796897171506953, las = 0.6326269983918267
    uas = 0.9914601098873779, las = 0.9908199288964026


2. MLP for English, minFreq = 5.

  #(features with count >= 5) = 80628

2.1. One hidden layer of 128 units: [128]


numFeatures = 2048

numFeatures = 4096
  0.8783439312025547,  0.9607473188446916

  numFeatures = 8192    
    0.8774475475503516, 0.9789231402144924
    uas = 0.3435814965471573, las = 0.2559833506763788
    uas = 0.3316137533252119, las = 0.24724660020386346

  numFeatures = 16384
    0.8821255497352867, 0.9895910174204166
    uas = 0.3955633336486614, las = 0.31789802289282
    uas = 0.3952465007582726, las = 0.32211048405141335

    numFeatures = 32768
    0.883190005322278, 0.9945596663451172
    uas = 0.3995837669094693, las = 0.3106139438085328
    uas = 0.4078512293961167, las = 0.3222410063893792

    numFeatures = 65536
    0.8856830723549679, 0.9967407649094933
    uas = 0.4070097436382556, las = 0.32433071611011255
    uas = 0.4082179350123064, las = 0.3284812172140318

    numFeatures = 80000


2.2 Two hidden layers of 128 units: [128, 128]

  numFeatures = 4096
    0.8800246505504355, 0.9451994552573342
    uas = 0.3322296849872292, las = 0.19931889130640432
    uas = 0.3241553340128782, las = 0.18628645302438904

  numFeatures = 8192
    0.8840863889744811, 0.9525974578675594
    uas = 0.31591145586983255, las = 0.2286917037177183
    uas = 0.3018670909678542, las = 0.21231012107500682

  numFeatures = 16384
    0.8839463290288243, 0.9690851444135504
    uas = 0.33256077949106044, las = 0.23332702677135558
    uas = 0.3181823832135843, las = 0.21655520473361012

  numFeatures = 32768
  ??? ADA1

